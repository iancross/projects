%
% Note: original labels
%{ tested_negative, tested_positive}
% changed to -1,1
% for comp135 assignment
%
% 1. Title: Pima Indians Diabetes Database
% 
% 2. Sources:
%    (a) Original owners: National Institute of Diabetes and Digestive and
%                         Kidney Diseases
%    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)
%                           Research Center, RMI Group Leader
%                           Applied Physics Laboratory
%                           The Johns Hopkins University
%                           Johns Hopkins Road
%                           Laurel, MD 20707
%                           (301) 953-6231
%    (c) Date received: 9 May 1990
% 
% 3. Past Usage:
%     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., \&
%        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast
%        the onset of diabetes mellitus.  In {\it Proceedings of the Symposium
%        on Computer Applications and Medical Care} (pp. 261--265).  IEEE
%        Computer Society Press.
% 
%        The diagnostic, binary-valued variable investigated is whether the
%        patient shows signs of diabetes according to World Health Organization
%        criteria (i.e., if the 2 hour post-load plasma glucose was at least 
%        200 mg/dl at any survey  examination or if found during routine medical
%        care).   The population lives near Phoenix, Arizona, USA.
% 
%        Results: Their ADAP algorithm makes a real-valued prediction between
%        0 and 1.  This was transformed into a binary decision using a cutoff of 
%        0.448.  Using 576 training instances, the sensitivity and specificity
%        of their algorithm was 76% on the remaining 192 instances.
% 
% 4. Relevant Information:
%       Several constraints were placed on the selection of these instances from
%       a larger database.  In particular, all patients here are females at
%       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning
%       routine that generates and executes digital analogs of perceptron-like
%       devices.  It is a unique algorithm; see the paper for details.
% 
% 5. Number of Instances: 768
% 
% 6. Number of Attributes: 8 plus class 
% 
% 7. For Each Attribute: (all numeric-valued)
%    1. Number of times pregnant
%    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test
%    3. Diastolic blood pressure (mm Hg)
%    4. Triceps skin fold thickness (mm)
%    5. 2-Hour serum insulin (mu U/ml)
%    6. Body mass index (weight in kg/(height in m)^2)
%    7. Diabetes pedigree function
%    8. Age (years)
%    9. Class variable (0 or 1)
% 
% 8. Missing Attribute Values: None
% 
% 9. Class Distribution: (class value 1 is interpreted as "tested positive for
%    diabetes")
% 
%    Class Value  Number of instances
%    0            500
%    1            268
% 
% 10. Brief statistical analysis:
% 
%     Attribute number:    Mean:   Standard Deviation:
%     1.                     3.8     3.4
%     2.                   120.9    32.0
%     3.                    69.1    19.4
%     4.                    20.5    16.0
%     5.                    79.8   115.2
%     6.                    32.0     7.9
%     7.                     0.5     0.3
%     8.                    33.2    11.8
% 
% 
%
%
%
%
% Relabeled values in attribute 'class'
%    From: 0                       To: tested_negative     
%    From: 1                       To: tested_positive     
%
@relation pima_diabetes
@attribute 'preg' numeric
@attribute 'plas' numeric
@attribute 'pres' numeric
@attribute 'skin' numeric
@attribute 'insu' numeric
@attribute 'mass' numeric
@attribute 'pedi' numeric
@attribute 'age' numeric
@attribute 'class' { -1, 1}
@data
0.0, 188.0, 82.0, 14.0, 185.0, 32.0, 0.682, 1.0,1
7.0, 194.0, 68.0, 28.0, 0.0, 35.9, 0.745, 1.0,1
7.0, 150.0, 78.0, 29.0, 126.0, 35.2, 0.692, 1.0,1
0.0, 141.0, 0.0, 0.0, 0.0, 42.4, 0.205, 1.0,1
7.0, 195.0, 70.0, 33.0, 145.0, 25.1, 0.163, 1.0,1
9.0, 122.0, 56.0, 0.0, 0.0, 33.3, 1.114, 1.0,1
7.0, 152.0, 88.0, 44.0, 0.0, 50.0, 0.337, 1.0,1
13.0, 104.0, 72.0, 0.0, 0.0, 31.2, 0.465, 1.0,1
1.0, 167.0, 74.0, 17.0, 144.0, 23.4, 0.447, 1.0,1
1.0, 149.0, 68.0, 29.0, 127.0, 29.3, 0.349, 1.0,1
3.0, 173.0, 78.0, 39.0, 185.0, 33.8, 0.97, 1.0,1
9.0, 102.0, 76.0, 37.0, 0.0, 32.9, 0.665, 1.0,1
5.0, 115.0, 76.0, 0.0, 0.0, 31.2, 0.343, 1.0,1
6.0, 104.0, 74.0, 18.0, 156.0, 29.9, 0.722, 1.0,1
0.0, 179.0, 90.0, 27.0, 0.0, 44.1, 0.686, 1.0,1
0.0, 189.0, 104.0, 25.0, 0.0, 34.3, 0.435, 1.0,1
1.0, 189.0, 60.0, 23.0, 846.0, 30.1, 0.398, 1.0,1
0.0, 128.0, 68.0, 19.0, 180.0, 30.5, 1.391, 1.0,1
0.0, 95.0, 85.0, 25.0, 36.0, 37.4, 0.247, 1.0,1
3.0, 107.0, 62.0, 13.0, 48.0, 22.9, 0.678, 1.0,1
10.0, 90.0, 85.0, 32.0, 0.0, 34.9, 0.825, 1.0,1
1.0, 128.0, 98.0, 41.0, 58.0, 32.0, 1.321, 1.0,1
1.0, 199.0, 76.0, 43.0, 0.0, 42.9, 1.394, 1.0,1
9.0, 164.0, 84.0, 21.0, 0.0, 30.8, 0.831, 1.0,1
5.0, 116.0, 74.0, 29.0, 0.0, 32.3, 0.66, 1.0,1
5.0, 136.0, 84.0, 41.0, 88.0, 35.0, 0.286, 1.0,1
4.0, 151.0, 90.0, 38.0, 0.0, 29.7, 0.294, 1.0,-1
4.0, 90.0, 0.0, 0.0, 0.0, 28.0, 0.61, 1.0,-1
6.0, 108.0, 44.0, 20.0, 130.0, 24.0, 0.813, 1.0,-1
3.0, 125.0, 58.0, 0.0, 0.0, 31.6, 0.151, 1.0,-1
4.0, 129.0, 60.0, 12.0, 231.0, 27.5, 0.527, 1.0,-1
5.0, 78.0, 48.0, 0.0, 0.0, 33.7, 0.654, 1.0,-1
2.0, 110.0, 74.0, 29.0, 125.0, 32.4, 0.698, 1.0,-1
2.0, 100.0, 68.0, 25.0, 71.0, 38.5, 0.324, 1.0,-1
3.0, 106.0, 72.0, 0.0, 0.0, 25.8, 0.207, 1.0,-1
2.0, 94.0, 76.0, 18.0, 66.0, 31.6, 0.649, 1.0,-1
1.0, 111.0, 86.0, 19.0, 0.0, 30.1, 0.143, 1.0,-1
3.0, 130.0, 64.0, 0.0, 0.0, 23.1, 0.314, 1.0,-1
3.0, 103.0, 72.0, 30.0, 152.0, 27.6, 0.73, 1.0,-1
3.0, 116.0, 0.0, 0.0, 0.0, 23.5, 0.187, 1.0,-1
1.0, 87.0, 60.0, 37.0, 75.0, 37.2, 0.509, 1.0,-1
1.0, 125.0, 70.0, 24.0, 110.0, 24.3, 0.221, 1.0,-1
2.0, 90.0, 70.0, 17.0, 0.0, 27.3, 0.085, 1.0,-1
2.0, 98.0, 60.0, 17.0, 120.0, 34.7, 0.198, 1.0,-1
3.0, 96.0, 56.0, 34.0, 115.0, 24.7, 0.944, 1.0,-1
3.0, 148.0, 66.0, 25.0, 0.0, 32.5, 0.256, 1.0,-1
1.0, 139.0, 62.0, 41.0, 480.0, 40.7, 0.536, 1.0,-1
7.0, 94.0, 64.0, 25.0, 79.0, 33.3, 0.738, 1.0,-1
5.0, 128.0, 80.0, 0.0, 0.0, 34.6, 0.144, 1.0,-1
3.0, 180.0, 64.0, 25.0, 70.0, 34.0, 0.271, 1.0,-1
4.0, 90.0, 88.0, 47.0, 54.0, 37.7, 0.362, 1.0,-1
7.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.305, 1.0,-1
3.0, 89.0, 74.0, 16.0, 85.0, 30.4, 0.551, 1.0,-1
2.0, 100.0, 54.0, 28.0, 105.0, 37.8, 0.498, 1.0,-1
1.0, 117.0, 60.0, 23.0, 106.0, 33.8, 0.466, 1.0,-1
1.0, 114.0, 66.0, 36.0, 200.0, 38.1, 0.289, 1.0,-1
2.0, 99.0, 60.0, 17.0, 160.0, 36.6, 0.453, 1.0,-1
4.0, 189.0, 110.0, 31.0, 0.0, 28.5, 0.68, 1.0,-1
10.0, 179.0, 70.0, 0.0, 0.0, 35.1, 0.2, 1.0,-1
5.0, 123.0, 74.0, 40.0, 77.0, 34.1, 0.269, 1.0,-1
1.0, 88.0, 78.0, 29.0, 76.0, 32.0, 0.365, 1.0,-1
5.0, 117.0, 92.0, 0.0, 0.0, 34.1, 0.337, 1.0,-1
10.0, 101.0, 76.0, 48.0, 180.0, 32.9, 0.171, 1.0,-1
1.0, 90.0, 68.0, 8.0, 0.0, 24.5, 1.138, 1.0,-1
4.0, 127.0, 88.0, 11.0, 155.0, 34.5, 0.598, 1.0,-1
1.0, 71.0, 78.0, 50.0, 45.0, 33.2, 0.422, 1.0,-1
4.0, 147.0, 74.0, 25.0, 293.0, 34.9, 0.385, 1.0,-1
0.0, 165.0, 90.0, 33.0, 680.0, 52.3, 0.427, 1.0,-1
3.0, 111.0, 56.0, 39.0, 0.0, 30.1, 0.557, 1.0,-1
0.0, 119.0, 64.0, 18.0, 92.0, 34.9, 0.725, 1.0,-1
0.0, 104.0, 64.0, 23.0, 116.0, 27.8, 0.454, 1.0,-1
1.0, 135.0, 54.0, 0.0, 0.0, 26.7, 0.687, 1.0,-1
0.0, 91.0, 68.0, 32.0, 210.0, 39.9, 0.381, 1.0,-1
0.0, 106.0, 70.0, 37.0, 148.0, 39.4, 0.605, 1.0,-1
2.0, 146.0, 76.0, 35.0, 194.0, 38.2, 0.329, 1.0,-1

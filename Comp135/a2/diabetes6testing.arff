%
% Note: original labels
%{ tested_negative, tested_positive}
% changed to -1,1
% for comp135 assignment
%
% 1. Title: Pima Indians Diabetes Database
% 
% 2. Sources:
%    (a) Original owners: National Institute of Diabetes and Digestive and
%                         Kidney Diseases
%    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)
%                           Research Center, RMI Group Leader
%                           Applied Physics Laboratory
%                           The Johns Hopkins University
%                           Johns Hopkins Road
%                           Laurel, MD 20707
%                           (301) 953-6231
%    (c) Date received: 9 May 1990
% 
% 3. Past Usage:
%     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., \&
%        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast
%        the onset of diabetes mellitus.  In {\it Proceedings of the Symposium
%        on Computer Applications and Medical Care} (pp. 261--265).  IEEE
%        Computer Society Press.
% 
%        The diagnostic, binary-valued variable investigated is whether the
%        patient shows signs of diabetes according to World Health Organization
%        criteria (i.e., if the 2 hour post-load plasma glucose was at least 
%        200 mg/dl at any survey  examination or if found during routine medical
%        care).   The population lives near Phoenix, Arizona, USA.
% 
%        Results: Their ADAP algorithm makes a real-valued prediction between
%        0 and 1.  This was transformed into a binary decision using a cutoff of 
%        0.448.  Using 576 training instances, the sensitivity and specificity
%        of their algorithm was 76% on the remaining 192 instances.
% 
% 4. Relevant Information:
%       Several constraints were placed on the selection of these instances from
%       a larger database.  In particular, all patients here are females at
%       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning
%       routine that generates and executes digital analogs of perceptron-like
%       devices.  It is a unique algorithm; see the paper for details.
% 
% 5. Number of Instances: 768
% 
% 6. Number of Attributes: 8 plus class 
% 
% 7. For Each Attribute: (all numeric-valued)
%    1. Number of times pregnant
%    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test
%    3. Diastolic blood pressure (mm Hg)
%    4. Triceps skin fold thickness (mm)
%    5. 2-Hour serum insulin (mu U/ml)
%    6. Body mass index (weight in kg/(height in m)^2)
%    7. Diabetes pedigree function
%    8. Age (years)
%    9. Class variable (0 or 1)
% 
% 8. Missing Attribute Values: None
% 
% 9. Class Distribution: (class value 1 is interpreted as "tested positive for
%    diabetes")
% 
%    Class Value  Number of instances
%    0            500
%    1            268
% 
% 10. Brief statistical analysis:
% 
%     Attribute number:    Mean:   Standard Deviation:
%     1.                     3.8     3.4
%     2.                   120.9    32.0
%     3.                    69.1    19.4
%     4.                    20.5    16.0
%     5.                    79.8   115.2
%     6.                    32.0     7.9
%     7.                     0.5     0.3
%     8.                    33.2    11.8
% 
% 
%
%
%
%
% Relabeled values in attribute 'class'
%    From: 0                       To: tested_negative     
%    From: 1                       To: tested_positive     
%
@relation pima_diabetes
@attribute 'preg' numeric
@attribute 'plas' numeric
@attribute 'pres' numeric
@attribute 'skin' numeric
@attribute 'insu' numeric
@attribute 'mass' numeric
@attribute 'pedi' numeric
@attribute 'age' numeric
@attribute 'class' { -1, 1}
@data
0.0, 126.0, 84.0, 29.0, 215.0, 30.7, 0.52, 1.0,-1
3.0, 111.0, 56.0, 39.0, 0.0, 30.1, 0.557, 1.0,-1
10.0, 129.0, 76.0, 28.0, 122.0, 35.9, 0.28, 1.0,-1
6.0, 80.0, 66.0, 30.0, 0.0, 26.2, 0.313, 1.0,-1
3.0, 122.0, 78.0, 0.0, 0.0, 23.0, 0.254, 1.0,-1
13.0, 106.0, 70.0, 0.0, 0.0, 34.2, 0.251, 1.0,-1
1.0, 113.0, 64.0, 35.0, 0.0, 33.6, 0.543, 1.0,1
5.0, 108.0, 72.0, 43.0, 75.0, 36.1, 0.263, 1.0,-1
0.0, 78.0, 88.0, 29.0, 40.0, 36.9, 0.434, 1.0,-1
7.0, 133.0, 88.0, 15.0, 155.0, 32.4, 0.262, 1.0,-1
9.0, 184.0, 85.0, 15.0, 0.0, 30.0, 1.213, 1.0,1
2.0, 100.0, 70.0, 52.0, 57.0, 40.5, 0.677, 1.0,-1
5.0, 77.0, 82.0, 41.0, 42.0, 35.8, 0.156, 1.0,-1
12.0, 106.0, 80.0, 0.0, 0.0, 23.6, 0.137, 1.0,-1
6.0, 119.0, 50.0, 22.0, 176.0, 27.1, 1.318, 1.0,1
2.0, 120.0, 76.0, 37.0, 105.0, 39.7, 0.215, 1.0,-1
0.0, 138.0, 0.0, 0.0, 0.0, 36.3, 0.933, 1.0,1
5.0, 96.0, 74.0, 18.0, 67.0, 33.6, 0.997, 1.0,-1
3.0, 191.0, 68.0, 15.0, 130.0, 30.9, 0.299, 1.0,-1
7.0, 161.0, 86.0, 0.0, 0.0, 30.4, 0.165, 1.0,1
2.0, 146.0, 0.0, 0.0, 0.0, 27.5, 0.24, 1.0,1
0.0, 161.0, 50.0, 0.0, 0.0, 21.9, 0.254, 1.0,-1
1.0, 157.0, 72.0, 21.0, 168.0, 25.6, 0.123, 1.0,-1
3.0, 115.0, 66.0, 39.0, 140.0, 38.1, 0.15, 1.0,-1
2.0, 108.0, 62.0, 32.0, 56.0, 25.2, 0.128, 1.0,-1
2.0, 112.0, 68.0, 22.0, 94.0, 34.1, 0.315, 1.0,-1
5.0, 155.0, 84.0, 44.0, 545.0, 38.7, 0.619, 1.0,-1
4.0, 123.0, 62.0, 0.0, 0.0, 32.0, 0.226, 1.0,1
0.0, 86.0, 68.0, 32.0, 0.0, 35.8, 0.238, 1.0,-1
3.0, 150.0, 76.0, 0.0, 0.0, 21.0, 0.207, 1.0,-1
3.0, 141.0, 0.0, 0.0, 0.0, 30.0, 0.761, 1.0,1
0.0, 146.0, 70.0, 0.0, 0.0, 37.9, 0.334, 1.0,1
3.0, 162.0, 52.0, 38.0, 0.0, 37.2, 0.652, 1.0,1
12.0, 92.0, 62.0, 7.0, 258.0, 27.6, 0.926, 1.0,1
1.0, 119.0, 86.0, 39.0, 220.0, 45.6, 0.808, 1.0,1
7.0, 106.0, 60.0, 24.0, 0.0, 26.5, 0.296, 1.0,1
1.0, 193.0, 50.0, 16.0, 375.0, 25.9, 0.655, 1.0,-1
4.0, 96.0, 56.0, 17.0, 49.0, 20.8, 0.34, 1.0,-1
0.0, 107.0, 62.0, 30.0, 74.0, 36.6, 0.757, 1.0,1
0.0, 165.0, 76.0, 43.0, 255.0, 47.9, 0.259, 1.0,-1
2.0, 108.0, 62.0, 10.0, 278.0, 25.3, 0.881, 1.0,-1
8.0, 118.0, 72.0, 19.0, 0.0, 23.1, 1.476, 1.0,-1
7.0, 136.0, 74.0, 26.0, 135.0, 26.0, 0.647, 1.0,-1
2.0, 108.0, 80.0, 0.0, 0.0, 27.0, 0.259, 1.0,1
5.0, 114.0, 74.0, 0.0, 0.0, 24.9, 0.744, 1.0,-1
3.0, 139.0, 54.0, 0.0, 0.0, 25.6, 0.402, 1.0,1
1.0, 71.0, 78.0, 50.0, 45.0, 33.2, 0.422, 1.0,-1
10.0, 101.0, 86.0, 37.0, 0.0, 45.6, 1.136, 1.0,1
0.0, 179.0, 90.0, 27.0, 0.0, 44.1, 0.686, 1.0,1
2.0, 87.0, 58.0, 16.0, 52.0, 32.7, 0.166, 1.0,-1
6.0, 134.0, 80.0, 37.0, 370.0, 46.2, 0.238, 1.0,1
4.0, 95.0, 70.0, 32.0, 0.0, 32.1, 0.612, 1.0,-1
10.0, 179.0, 70.0, 0.0, 0.0, 35.1, 0.2, 1.0,-1
2.0, 112.0, 75.0, 32.0, 0.0, 35.7, 0.148, 1.0,-1
4.0, 171.0, 72.0, 0.0, 0.0, 43.6, 0.479, 1.0,1
2.0, 128.0, 64.0, 42.0, 0.0, 40.0, 1.101, 1.0,-1
2.0, 114.0, 68.0, 22.0, 0.0, 28.7, 0.092, 1.0,-1
6.0, 151.0, 62.0, 31.0, 120.0, 35.5, 0.692, 1.0,-1
11.0, 155.0, 76.0, 28.0, 150.0, 33.3, 1.353, 1.0,1
3.0, 142.0, 80.0, 15.0, 0.0, 32.4, 0.2, 1.0,-1
0.0, 102.0, 52.0, 0.0, 0.0, 25.1, 0.078, 1.0,-1
2.0, 128.0, 78.0, 37.0, 182.0, 43.3, 1.224, 1.0,1
3.0, 113.0, 50.0, 10.0, 85.0, 29.5, 0.626, 1.0,-1
8.0, 112.0, 72.0, 0.0, 0.0, 23.6, 0.84, 1.0,-1
0.0, 104.0, 64.0, 23.0, 116.0, 27.8, 0.454, 1.0,-1
0.0, 106.0, 70.0, 37.0, 148.0, 39.4, 0.605, 1.0,-1
9.0, 164.0, 84.0, 21.0, 0.0, 30.8, 0.831, 1.0,1
6.0, 105.0, 70.0, 32.0, 68.0, 30.8, 0.122, 1.0,-1
7.0, 181.0, 84.0, 21.0, 192.0, 35.9, 0.586, 1.0,1
4.0, 129.0, 60.0, 12.0, 231.0, 27.5, 0.527, 1.0,-1
1.0, 95.0, 60.0, 18.0, 58.0, 23.9, 0.26, 1.0,-1
1.0, 128.0, 48.0, 45.0, 194.0, 40.5, 0.613, 1.0,1
4.0, 142.0, 86.0, 0.0, 0.0, 44.0, 0.645, 1.0,1
3.0, 99.0, 80.0, 11.0, 64.0, 19.3, 0.284, 1.0,-1
0.0, 137.0, 68.0, 14.0, 148.0, 24.8, 0.143, 1.0,-1
